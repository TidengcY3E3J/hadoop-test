[INFO ] 2016-09-09 16:05:45 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 16:05:55 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:05:55 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:12:55 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 16:13:06 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:13:06 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:14:39 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 16:14:49 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:14:49 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:15:37 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 16:15:48 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:15:48 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:23:44 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:23:44 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:24:17 org.apache.hadoop.conf.Configuration@(Configuration.java:1173):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:24:17 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:27:14 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:27:14 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [WARN ] 2016-09-09 16:27:15 org.apache.hadoop.mapreduce.JobResourceUploader@(JobResourceUploader.java:171):No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 [INFO ] 2016-09-09 16:27:15 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 16:27:15 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1388358693_0001
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1388358693_0001
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 16:27:16 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1388358693_0001_m_000000_0
 [INFO ] 2016-09-09 16:27:17 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:27:17 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1388358693_0001 running in uber mode : false
 [INFO ] 2016-09-09 16:27:17 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 16:27:17 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@212ecc
 [INFO ] 2016-09-09 16:27:17 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1388358693_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1388358693_0001_m_000000_0' done.
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1388358693_0001_m_000000_0
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1388358693_0001_r_000000_0
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@19a9ea0
 [INFO ] 2016-09-09 16:27:18 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1115546
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1388358693_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1388358693_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1388358693_0001_m_000000_0
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1388358693_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1388358693_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1388358693_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1388358693_0001_r_000000
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1388358693_0001_r_000000_0' done.
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1388358693_0001_r_000000_0
 [INFO ] 2016-09-09 16:27:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 16:27:20 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 16:27:20 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1388358693_0001 completed successfully
 [INFO ] 2016-09-09 16:27:20 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=9280
		FILE: Number of bytes written=546035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 16:34:31 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 16:34:42 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:34:42 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 16:53:51 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:53:51 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [WARN ] 2016-09-09 16:53:51 org.apache.hadoop.mapreduce.JobResourceUploader@(JobResourceUploader.java:171):No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 [INFO ] 2016-09-09 16:53:52 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 16:53:52 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1376721583_0001
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1376721583_0001
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 16:53:53 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1376721583_0001_m_000000_0
 [INFO ] 2016-09-09 16:53:54 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:53:54 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1376721583_0001 running in uber mode : false
 [INFO ] 2016-09-09 16:53:54 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b25689
 [INFO ] 2016-09-09 16:53:54 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 16:53:54 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 16:53:55 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1376721583_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1376721583_0001_m_000000_0' done.
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1376721583_0001_m_000000_0
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1376721583_0001_r_000000_0
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:54:03 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16e1f79
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14bc361
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1376721583_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1376721583_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1376721583_0001_m_000000_0
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 16:54:04 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1376721583_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1376721583_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1376721583_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1376721583_0001_r_000000
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1376721583_0001_r_000000_0' done.
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1376721583_0001_r_000000_0
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1376721583_0001 completed successfully
 [INFO ] 2016-09-09 16:54:05 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=9280
		FILE: Number of bytes written=546035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=93
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 16:54:46 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 16:54:46 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [WARN ] 2016-09-09 16:54:46 org.apache.hadoop.mapreduce.JobResourceUploader@(JobResourceUploader.java:171):No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 [INFO ] 2016-09-09 16:54:46 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 16:54:46 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 16:54:46 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1717531641_0001
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1717531641_0001
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1717531641_0001_m_000000_0
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1e9436c
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 16:54:47 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 16:55:09 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1717531641_0001 running in uber mode : false
 [INFO ] 2016-09-09 16:55:09 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1717531641_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1717531641_0001_m_000000_0' done.
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1717531641_0001_m_000000_0
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1717531641_0001_r_000000_0
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f56650
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b8217
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1717531641_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1717531641_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1717531641_0001_m_000000_0
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 16:55:10 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1717531641_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1717531641_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1717531641_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1717531641_0001_r_000000
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1717531641_0001_r_000000_0' done.
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1717531641_0001_r_000000_0
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1717531641_0001 completed successfully
 [INFO ] 2016-09-09 16:55:11 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=9280
		FILE: Number of bytes written=546035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=62
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 17:28:28 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 17:28:28 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
 [INFO ] 2016-09-09 17:28:44 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 17:28:44 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 17:28:45 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 17:28:45 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 17:28:45 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):fs.default.name is deprecated. Instead, use fs.defaultFS
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1602966607_0001
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1602966607_0001
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1602966607_0001_m_000000_0
 [INFO ] 2016-09-09 17:28:46 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6abe27
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1602966607_0001 running in uber mode : false
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1602966607_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1602966607_0001_m_000000_0' done.
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1602966607_0001_m_000000_0
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1602966607_0001_r_000000_0
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ebccf4
 [INFO ] 2016-09-09 17:28:47 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@155a847
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1602966607_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1602966607_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1602966607_0001_m_000000_0
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1602966607_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 17:28:48 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1602966607_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 17:28:49 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1602966607_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1602966607_0001_r_000000
 [INFO ] 2016-09-09 17:28:49 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 17:28:49 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1602966607_0001_r_000000_0' done.
 [INFO ] 2016-09-09 17:28:49 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1602966607_0001_r_000000_0
 [INFO ] 2016-09-09 17:28:49 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 17:28:50 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 17:28:52 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1602966607_0001 completed successfully
 [INFO ] 2016-09-09 17:28:52 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=26640
		FILE: Number of bytes written=565953
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 18:14:16 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 18:14:16 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 18:14:16 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1774715362_0001
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1774715362_0001
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 18:14:17 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1774715362_0001_m_000000_0
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@174467
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1774715362_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:14:18 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1774715362_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1774715362_0001_m_000000_0' done.
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1774715362_0001_m_000000_0
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1774715362_0001_r_000000_0
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@120bca1
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12fcc41
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1774715362_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1774715362_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1774715362_0001_m_000000_0
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:14:19 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 18:14:20 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1774715362_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1774715362_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1774715362_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1774715362_0001_r_000000
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1774715362_0001_r_000000_0' done.
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1774715362_0001_r_000000_0
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1774715362_0001 completed successfully
 [INFO ] 2016-09-09 18:14:22 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=26640
		FILE: Number of bytes written=565035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=62
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 18:17:55 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 18:17:55 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1072567292_0001
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1072567292_0001
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1072567292_0001_m_000000_0
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7c78c1
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 18:17:56 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1072567292_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1072567292_0001_m_000000_0' done.
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1072567292_0001_m_000000_0
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1072567292_0001_r_000000_0
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ec57ce
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@408eb0
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1072567292_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1072567292_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1072567292_0001_m_000000_0
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1072567292_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:17:57 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1072567292_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1072567292_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1072567292_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1072567292_0001_r_000000
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1072567292_0001_r_000000_0' done.
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1072567292_0001_r_000000_0
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 18:17:58 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 18:17:59 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1072567292_0001 completed successfully
 [INFO ] 2016-09-09 18:17:59 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=26640
		FILE: Number of bytes written=565035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=54
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 18:19:50 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:19:52 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:19:53 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:19:53 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473416230301_0001
 [INFO ] 2016-09-09 18:19:54 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473416230301_0001
 [INFO ] 2016-09-09 18:19:55 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473416230301_0001/
 [INFO ] 2016-09-09 18:19:55 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473416230301_0001
 [INFO ] 2016-09-09 18:20:06 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473416230301_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:20:06 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:20:06 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473416230301_0001 failed with state FAILED due to: Application application_1473416230301_0001 failed 2 times due to AM Container for appattempt_1473416230301_0001_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473416230301_0001/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473416230301_0001_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:20:06 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:23:30 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:25:29 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:25:30 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:25:30 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473416230301_0002
 [INFO ] 2016-09-09 18:25:33 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:35 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:37 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:39 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:41 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:43 org.apache.hadoop.ipc.Client$Connection@(Client.java:859):Retrying connect to server: localhost/127.0.0.1:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 [INFO ] 2016-09-09 18:25:45 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473416230301_0002
 [INFO ] 2016-09-09 18:25:45 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473416230301_0002/
 [INFO ] 2016-09-09 18:25:45 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473416230301_0002
 [INFO ] 2016-09-09 18:25:55 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473416230301_0002 running in uber mode : false
 [INFO ] 2016-09-09 18:25:55 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:25:55 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473416230301_0002 failed with state FAILED due to: Application application_1473416230301_0002 failed 2 times due to AM Container for appattempt_1473416230301_0002_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473416230301_0002/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473416230301_0002_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:25:55 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:29:04 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:29:06 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:29:07 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:29:07 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473416743663_0001
 [INFO ] 2016-09-09 18:29:08 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473416743663_0001
 [INFO ] 2016-09-09 18:29:08 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473416743663_0001/
 [INFO ] 2016-09-09 18:29:08 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473416743663_0001
 [INFO ] 2016-09-09 18:29:14 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473416743663_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:29:14 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:29:14 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473416743663_0001 failed with state FAILED due to: Application application_1473416743663_0001 failed 2 times due to AM Container for appattempt_1473416743663_0001_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473416743663_0001/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473416743663_0001_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:29:14 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:29:29 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:29:31 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:29:31 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:29:32 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473416743663_0002
 [INFO ] 2016-09-09 18:29:32 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473416743663_0002
 [INFO ] 2016-09-09 18:29:32 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473416743663_0002/
 [INFO ] 2016-09-09 18:29:32 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473416743663_0002
 [INFO ] 2016-09-09 18:29:38 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473416743663_0002 running in uber mode : false
 [INFO ] 2016-09-09 18:29:38 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:29:38 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473416743663_0002 failed with state FAILED due to: Application application_1473416743663_0002 failed 2 times due to AM Container for appattempt_1473416743663_0002_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473416743663_0002/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473416743663_0002_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:29:38 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:37:39 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:38:04 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:38:06 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:38:08 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473417433711_0001
 [INFO ] 2016-09-09 18:38:08 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473417433711_0001
 [INFO ] 2016-09-09 18:38:09 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473417433711_0001/
 [INFO ] 2016-09-09 18:38:09 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473417433711_0001
 [INFO ] 2016-09-09 18:38:17 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473417433711_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:38:17 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:38:17 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473417433711_0001 failed with state FAILED due to: Application application_1473417433711_0001 failed 2 times due to AM Container for appattempt_1473417433711_0001_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473417433711_0001/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473417433711_0001_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:38:17 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:39:11 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:39:41 org.apache.hadoop.yarn.client.RMProxy@(RMProxy.java:98):Connecting to ResourceManager at localhost/127.0.0.1:8032
 [INFO ] 2016-09-09 18:39:42 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:39:43 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:39:43 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_1473417433711_0002
 [INFO ] 2016-09-09 18:39:43 org.apache.hadoop.yarn.client.api.impl.YarnClientImpl@(YarnClientImpl.java:251):Submitted application application_1473417433711_0002
 [INFO ] 2016-09-09 18:39:43 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://AFODC-605201126:8088/proxy/application_1473417433711_0002/
 [INFO ] 2016-09-09 18:39:43 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_1473417433711_0002
 [INFO ] 2016-09-09 18:39:51 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_1473417433711_0002 running in uber mode : false
 [INFO ] 2016-09-09 18:39:51 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:39:51 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_1473417433711_0002 failed with state FAILED due to: Application application_1473417433711_0002 failed 2 times due to AM Container for appattempt_1473417433711_0002_000002 exited with  exitCode: 2
For more detailed output, check application tracking page:http://AFODC-605201126:8088/proxy/application_1473417433711_0002/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1473417433711_0002_02_000001
Exit code: 2
Exception message: No privilege to create symbolic links.

Stack trace: ExitCodeException exitCode=2: No privilege to create symbolic links.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Shell output: 移动了         1 个文件。
os version=6


Container exited with a non-zero exit code 2
Failing this attempt. Failing the application.
 [INFO ] 2016-09-09 18:39:51 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 18:48:48 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 18:48:48 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local903276236_0001
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local903276236_0001
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 18:48:49 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 18:48:50 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 18:48:50 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local903276236_0001_m_000000_0
 [INFO ] 2016-09-09 18:48:50 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:48:50 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local903276236_0001 running in uber mode : false
 [INFO ] 2016-09-09 18:48:50 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 18:48:51 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1dbe345
 [INFO ] 2016-09-09 18:48:51 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 18:48:52 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local903276236_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local903276236_0001_m_000000_0' done.
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local903276236_0001_m_000000_0
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local903276236_0001_r_000000_0
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 18:48:59 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b41a65
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@142991e
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local903276236_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local903276236_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local903276236_0001_m_000000_0
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 18:49:00 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:49:01 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 18:49:02 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local903276236_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 18:49:02 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 18:49:02 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local903276236_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local903276236_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local903276236_0001_r_000000
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local903276236_0001_r_000000_0' done.
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local903276236_0001_r_000000_0
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 18:49:03 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local903276236_0001 completed successfully
 [INFO ] 2016-09-09 18:49:04 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=26640
		FILE: Number of bytes written=562271
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=104
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 19:41:54 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 19:41:54 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 19:41:55 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 19:41:55 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 19:41:56 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1870811459_0001
 [INFO ] 2016-09-09 19:41:56 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 19:41:56 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1870811459_0001
 [INFO ] 2016-09-09 19:41:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 19:41:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1870811459_0001_m_000000_0
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@19addb1
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1870811459_0001 running in uber mode : false
 [INFO ] 2016-09-09 19:41:57 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 19:48:58 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 19:48:58 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 19:48:58 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1819922369_0001
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1819922369_0001
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 19:48:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1819922369_0001_m_000000_0
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a631b
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1819922369_0001 running in uber mode : false
 [INFO ] 2016-09-09 19:49:00 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1475):Spilling map output
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1476):bufstart = 0; bufend = 5988; bufvoid = 104857600
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1478):kvstart = 26214396(104857584); kvend = 26212240(104848960); length = 2157/6553600
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1660):Finished spill 0
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1819922369_0001_m_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):map
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1819922369_0001_m_000000_0' done.
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:249):Finishing task: attempt_local1819922369_0001_m_000000_0
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for reduce tasks
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:302):Starting task: attempt_local1819922369_0001_r_000000_0
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@45a62e
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.ReduceTask@(ReduceTask.java:362):Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@8d298d
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:197):MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:61):attempt_local1819922369_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher@(LocalFetcher.java:141):localfetcher#1 about to shuffle output of map attempt_local1819922369_0001_m_000000_0 decomp: 4451 len: 4455 to MEMORY
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput@(InMemoryMapOutput.java:100):Read 4451 bytes from map-output for attempt_local1819922369_0001_m_000000_0
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:315):closeInMemoryFile -> map-output of size: 4451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4451
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.EventFetcher@(EventFetcher.java:76):EventFetcher is interrupted.. Returning
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:687):finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:754):Merged 1 segments, 4451 bytes to disk to satisfy reduce memory limit
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:784):Merging 1 files, 4455 bytes from disk
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl@(MergeManagerImpl.java:799):Merging 0 segments, 0 bytes from memory into reduce
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:597):Merging 1 sorted segments
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.Merger$MergeQueue@(Merger.java:696):Down to the last merge-pass, with 1 segments left of total size: 4448 bytes
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 19:49:01 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 0%
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.Task@(Task.java:1001):Task:attempt_local1819922369_0001_r_000000_0 is done. And is in the process of committing
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):1 / 1 copied.
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.Task@(Task.java:1162):Task attempt_local1819922369_0001_r_000000_0 is allowed to commit now
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@(FileOutputCommitter.java:439):Saved output of task 'attempt_local1819922369_0001_r_000000_0' to hdfs://localhost:9000/user/fkong/output/_temporary/0/task_local1819922369_0001_r_000000
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:591):reduce > reduce
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.Task@(Task.java:1121):Task 'attempt_local1819922369_0001_r_000000_0' done.
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable@(LocalJobRunner.java:325):Finishing task: attempt_local1819922369_0001_r_000000_0
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):reduce task executor complete.
 [INFO ] 2016-09-09 19:49:02 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 100% reduce 100%
 [INFO ] 2016-09-09 19:49:03 org.apache.hadoop.mapreduce.Job@(Job.java:1385):Job job_local1819922369_0001 completed successfully
 [INFO ] 2016-09-09 19:49:03 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 38
	File System Counters
		FILE: Number of bytes read=27000
		FILE: Number of bytes written=565391
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=7854
		HDFS: Number of bytes written=3355
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=99
		Map output records=540
		Map output bytes=5988
		Map output materialized bytes=4455
		Input split bytes=107
		Combine input records=540
		Combine output records=275
		Reduce input groups=275
		Reduce shuffle bytes=4455
		Reduce input records=275
		Reduce output records=275
		Spilled Records=550
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=57
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3927
	File Output Format Counters 
		Bytes Written=3355
 [INFO ] 2016-09-09 21:30:11 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:30:11 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:30:12 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:30:12 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:30:13 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local489647769_0001
 [INFO ] 2016-09-09 21:30:13 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:30:13 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local489647769_0001
 [INFO ] 2016-09-09 21:30:13 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:30:13 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:30:14 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:30:14 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local489647769_0001_m_000000_0
 [INFO ] 2016-09-09 21:30:14 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local489647769_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:30:14 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:30:14 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:30:15 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37268e
 [INFO ] 2016-09-09 21:30:15 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:30:16 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local489647769_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:30:17 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local489647769_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:30:17 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:32:18 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:32:18 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local490141005_0001
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local490141005_0001
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local490141005_0001_m_000000_0
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4e63f5
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:32:19 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:32:20 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local490141005_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local490141005_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local490141005_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:32:20 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:35:38 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:35:38 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:35:38 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:35:38 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1550215873_0001
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1550215873_0001
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1550215873_0001_m_000000_0
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@849d45
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:35:39 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local1550215873_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:35:40 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1550215873_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:35:40 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:35:40 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local1550215873_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:35:40 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:38:22 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:38:22 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:38:23 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:250):Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/Administrator1790363646/.staging/job_local1790363646_0001
 [INFO ] 2016-09-09 21:38:58 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:38:58 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local84756898_0001
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local84756898_0001
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local84756898_0001_m_000000_0
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@dddc70
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:38:59 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local84756898_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:39:00 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local84756898_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:39:00 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:39:00 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local84756898_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:39:00 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:43:06 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:43:06 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local833148224_0001
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local833148224_0001
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:43:07 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local833148224_0001_m_000000_0
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1e833ff
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local833148224_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:43:08 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:43:09 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local833148224_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:43:10 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local833148224_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:43:10 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:45:23 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:45:23 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:45:23 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:45:23 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:45:23 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local733166550_0001
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local733166550_0001
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local733166550_0001_m_000000_0
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d9347d
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:45:24 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 21:45:25 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local733166550_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:45:25 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [WARN ] 2016-09-09 21:45:25 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local733166550_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:45:26 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local733166550_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:45:26 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1963022363_0001
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1963022363_0001
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:58:53 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1963022363_0001_m_000000_0
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c7e20a
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [WARN ] 2016-09-09 21:58:54 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:560):job_local1963022363_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1069)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:712)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local1963022363_0001 running in uber mode : false
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapreduce.Job@(Job.java:1387):Job job_local1963022363_0001 failed with state FAILED due to: NA
 [INFO ] 2016-09-09 21:58:54 org.apache.hadoop.mapreduce.Job@(Job.java:1392):Counters: 0
 [INFO ] 2016-09-09 21:59:36 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 21:59:36 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 21:59:36 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local51020775_0001
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local51020775_0001
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local51020775_0001_m_000000_0
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c7e20a
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 21:59:37 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 21:59:38 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local51020775_0001 running in uber mode : false
 [INFO ] 2016-09-09 22:15:56 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 22:15:56 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 [INFO ] 2016-09-09 22:15:56 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:456):map task executor complete.
 [INFO ] 2016-09-09 22:16:40 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 22:16:40 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 22:16:40 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 22:16:40 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 22:16:40 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local1800531318_0001
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local1800531318_0001
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local1800531318_0001_m_000000_0
 [INFO ] 2016-09-09 22:16:41 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 22:17:29 org.apache.hadoop.conf.Configuration@(Configuration.java:1129):session.id is deprecated. Instead, use dfs.metrics.session-id
 [INFO ] 2016-09-09 22:17:29 org.apache.hadoop.metrics.jvm.JvmMetrics@(JvmMetrics.java:76):Initializing JVM Metrics with processName=JobTracker, sessionId=
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapreduce.lib.input.FileInputFormat@(FileInputFormat.java:281):Total input paths to process : 1
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:199):number of splits:1
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapreduce.JobSubmitter@(JobSubmitter.java:288):Submitting tokens for job: job_local98689973_0001
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapreduce.Job@(Job.java:1301):The url to track the job: http://localhost:8080/
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapreduce.Job@(Job.java:1346):Running job: job_local98689973_0001
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:471):OutputCommitter set in config null
 [INFO ] 2016-09-09 22:17:30 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:489):OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.LocalJobRunner$Job@(LocalJobRunner.java:448):Waiting for map tasks
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable@(LocalJobRunner.java:224):Starting task: attempt_local98689973_0001_m_000000_0
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree@(ProcfsBasedProcessTree.java:181):ProcfsBasedProcessTree currently is supported only on Linux.
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.Task@(Task.java:587): Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@110ad01
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask@(MapTask.java:753):Processing split: hdfs://localhost:9000/user/fkong/README.md:0+3927
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1202):(EQUATOR) 0 kvi 26214396(104857584)
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:995):mapreduce.task.io.sort.mb: 100
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:996):soft limit at 83886080
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:997):bufstart = 0; bufvoid = 104857600
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:998):kvstart = 26214396; length = 6553600
 [INFO ] 2016-09-09 22:17:31 org.apache.hadoop.mapred.MapTask@(MapTask.java:402):Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 [INFO ] 2016-09-09 22:17:40 org.apache.hadoop.mapreduce.Job@(Job.java:1367):Job job_local98689973_0001 running in uber mode : false
 [INFO ] 2016-09-09 22:17:41 org.apache.hadoop.mapreduce.Job@(Job.java:1374): map 0% reduce 0%
 [INFO ] 2016-09-09 22:18:12 org.apache.hadoop.mapred.MapTask$MapOutputBuffer@(MapTask.java:1457):Starting flush of map output
 